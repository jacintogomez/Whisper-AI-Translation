{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install torch"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install transformers"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install accelerate"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import accelerate\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d62e1f5b8a14fef853e50a9744d0c3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/3.90k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5198b4d9817401f9171f3cb48946138"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "WhisperForConditionalGeneration(\n  (model): WhisperModel(\n    (encoder): WhisperEncoder(\n      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n      (embed_positions): Embedding(1500, 1280)\n      (layers): ModuleList(\n        (0-31): 32 x WhisperEncoderLayer(\n          (self_attn): WhisperSdpaAttention(\n            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): WhisperDecoder(\n      (embed_tokens): Embedding(51866, 1280, padding_idx=50256)\n      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n      (layers): ModuleList(\n        (0-31): 32 x WhisperDecoderLayer(\n          (self_attn): WhisperSdpaAttention(\n            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): WhisperSdpaAttention(\n            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-base\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype,\n",
    "    use_safetensors=True\n",
    ")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc038f67173a49b490d729ae6c775ada"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cff59b343e6c4075aea01e3bc8a7cf11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51fe909366b84f9b8330956b8fe0364a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae8584ae7a7740ec8af79d3d3502106b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbc19cc6115c4f9083a8f84b8501b809"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2413fb725f674c6a962cfd8c7d381a13"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b17d6c256b334599ac374dbfdc95583e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "842884de37f14dc987802d57f9548f48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import ffmpeg\n",
    "\n",
    "def recordaudio(filename,duration=3,fs=44100):\n",
    "    print('recording...')\n",
    "    recording=sd.rec(int(duration*fs),samplerate=fs,channels=1)\n",
    "    sd.wait() #wait for recording to finish\n",
    "    print('done waiting')\n",
    "    write(filename,fs,recording) #wave WAV file\n",
    "    print('done writing')\n",
    "    result=pipe(filename,generate_kwargs={'language':'en'})\n",
    "    print(result['text'])\n",
    "    print(f'finished recording, file saved as {filename}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "result=pipe('/Users/jacintogomez/PycharmProjects/whisper/test.wav',generate_kwargs={'language':'en'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' it', 'chunks': [{'timestamp': (0.0, 3.0), 'text': ' it'}]}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n",
      "done waiting\n",
      "done writing\n",
      " I'm trying something now.\n",
      "finished recording, file saved as test.wav\n"
     ]
    }
   ],
   "source": [
    "recordaudio(\"test.wav\", duration=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
